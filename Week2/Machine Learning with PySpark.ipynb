{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile('/datasets/host_server_requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae027852de73d98e3776430bff639156",
     "grade": false,
     "grade_id": "cell-244fd5f7c0138b60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#a = requests_rdd.take(1)[0]\n",
    "def process_line(x):\n",
    "    ls = []\n",
    "    x = x.split(\"|\")\n",
    "    for j in range(len(x)):\n",
    "        if \" => \" in x[j]:\n",
    "            d = x[j].split(\" => \")\n",
    "            ls.append(float(d[0]))\n",
    "            ls.append(float(d[1]))\n",
    "        else:\n",
    "            if x[j] == \"SERVER\":\n",
    "                ls.append(0.0)\n",
    "            elif x[j]==\"HOST\":\n",
    "                ls.append(1.0)\n",
    "            else:\n",
    "                ls.append(float(x[j]))\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it here\n",
    "rdd1 = requests_rdd.map(process_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fe0fd15181720aed141c4ccf80f4bbd",
     "grade": true,
     "grade_id": "cell-b4947d69e22e2f22",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "887c47376104f469159443a9dbe2c2d9",
     "grade": false,
     "grade_id": "cell-b3baf345ff984885",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests_df = rdd1.toDF()\n",
    "requests_df = requests_df.withColumnRenamed(\"_1\",\"f1\").withColumnRenamed(\"_2\",\"f2\").withColumnRenamed(\"_3\",\"f3\").withColumnRenamed(\"_4\",\"f4\").withColumnRenamed(\"_5\",\"f5\").withColumnRenamed(\"_6\",\"f6\").withColumnRenamed(\"_7\",\"f7\").withColumnRenamed(\"_8\",\"f8\").withColumnRenamed(\"_9\",\"label\")\n",
    "type(requests_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d0ecca803966f38a4c48122772e830e",
     "grade": true,
     "grade_id": "cell-333768d7c8281274",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel` and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f95851055354ab8dc2ec05ccf7c57ec9",
     "grade": false,
     "grade_id": "cell-15727d5a477764c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------------------+\n",
      "| f1|          semlabel|             mlabel|\n",
      "+---+------------------+-------------------+\n",
      "|0.0|1.7554606758419875|-29.611753412328927|\n",
      "|1.0|1.7481077347771363| -12.62243193686321|\n",
      "+---+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlbs = requests_df.groupBy(\"f1\").agg({\"label\":\"mean\"})\n",
    "mlbs = mlbs.withColumnRenamed(\"avg(label)\",\"mlabel\")\n",
    "\n",
    "stlbs = requests_df.groupBy('f1').agg({\"label\":\"stddev_samp\"})\n",
    "#stlbs.show(2)\n",
    "nlbs = requests_df.groupBy('f1').agg({\"label\":\"count\"})\n",
    "#nlbs.show(2)\n",
    "summary_df = stlbs.join(nlbs,'f1')\n",
    "#summary_df.show(2)\n",
    "summary_df = summary_df.withColumn(\"semlabel\",stlbs[\"stddev_samp(label)\"]/fn.sqrt(nlbs[\"count(label)\"])) \n",
    "summary_df = summary_df.join(mlbs,\"f1\")\n",
    "summary_df = summary_df.drop(\"stddev_samp(label)\",\"count(label)\")\n",
    "summary_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01274b653620c538a46bccfa72ef3b1c",
     "grade": true,
     "grade_id": "cell-0f48704616a8f55c",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919213,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically, we say that a mean $\\overline{x}$ is *statistically* different from another mean $\\overline{y}$ if it is not within 2 standard errors of the mean of x (i.e., $\\overline{y} \\not\\in \\{\\overline{x} \\pm 2\\text{SE}(x)\\}$). Discuss whether you think the mean label for f1 = 0 is statistically different from the mean label for f1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------------------+\n",
      "| f1|          semlabel|             mlabel|\n",
      "+---+------------------+-------------------+\n",
      "|0.0|1.7554606758419875|-29.611753412328927|\n",
      "|1.0|1.7481077347771363| -12.62243193686321|\n",
      "+---+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display it to make your argument\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 pts for your answer below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "47b519124f162219100057c7b90984ba",
     "grade": true,
     "grade_id": "cell-55c3ae319a99bc6c",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "### Summary\n",
    "#### For f1 = 0.0:\n",
    "$semlabel_0$ = 1.7554606758419875\n",
    "\n",
    "$mlabel_0$ = -29.611753412328927\n",
    "\n",
    "#### For f1 = 1.0:\n",
    "$semlabel_1$ = 1.7481077347771363\n",
    "\n",
    "$mlabel_1$ = -12.62243193686321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `va` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b8e718f4d06bf724fb9be5673a5ad75",
     "grade": false,
     "grade_id": "cell-56d045d1b2c78b89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "va = VectorAssembler(inputCols=[\"f1\", \"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\"],outputCol=\"features\")\n",
    "features_df = va.transform(requests_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "| f1|     f2|      f3|      f4|      f5|     f6|      f7|      f8|         label|            features|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "|0.0| 8.0E-5| 0.45592| 0.25362|-0.12878|-0.0693| -0.1474|-0.53736|-106.947151761|[0.0,8.0E-5,0.455...|\n",
      "|0.0|-1.0E-5| 0.10405|-0.17047| 0.10127|0.13776| 0.66619| 0.32221| 127.061566761|[0.0,-1.0E-5,0.10...|\n",
      "|1.0|-1.0E-5|-0.72394| 0.31161| 0.06975| 0.0086|-0.44817|-0.22976|-170.222653879|[1.0,-1.0E-5,-0.7...|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f41db05c38db0e4e7325099be89cd82",
     "grade": true,
     "grade_id": "cell-505b09bb3262a7ad",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf7c8c1d895958b567e5aae92cf6a2e0",
     "grade": false,
     "grade_id": "cell-73fa24e4562cc788",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761|  -98.1371488916323|\n",
      "| 127.061566761|  107.1452180178212|\n",
      "|-170.222653879|-164.65768779095717|\n",
      "|-127.850350049|-108.04111399145371|\n",
      "|-110.295233798|-109.93527884136866|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "lr = regression.LinearRegression(featuresCol=\"features\",labelCol=\"label\",maxIter=10, regParam=0.4, elasticNetParam=0.9)\n",
    "lr_model = lr.fit(features_df)\n",
    "\n",
    "predictions_df = lr_model.transform(features_df)\n",
    "predictions_df = predictions_df.select(\"label\",\"prediction\")\n",
    "predictions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17142a6e7131d10366b0dc029fdf1b1e",
     "grade": true,
     "grade_id": "cell-966429bd3d48aa0a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(va), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `rmse_df` that contains the root mean squared error in column `rmse` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33a4b6cd52e592b1234d54a918a0550c",
     "grade": false,
     "grade_id": "cell-926f142075117a76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.559748270091829|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "rms = predictions_df.withColumn(\"error\",(predictions_df[\"prediction\"]-predictions_df[\"label\"]))\n",
    "rms = rms.withColumn(\"squared error\",(rms[\"error\"]**2))\n",
    "\n",
    "rmse_df = rms.groupBy().agg({\"squared error\":\"sum\"})\n",
    "n = rms.groupBy().agg({\"error\":\"count\"}).collect()[0][0]\n",
    "\n",
    "rmse_df = rmse_df.withColumn(\"rmse\", fn.sqrt((1/n*rmse_df[\"sum(squared error)\"])))\n",
    "rmse_df = rmse_df.drop(\"sum(squared error)\")\n",
    "rmse_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cab72e6d6c675bca35428c189508d683",
     "grade": true,
     "grade_id": "cell-ce1df3212ea78b19",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_less(rmse_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Add the constant 10 to each feature in `requests_df` and redo the analytics pipeline from Q5, creating a vector assembler `va2`, `features2_df`, `lr_model2`, and `predictions2_df`. When adding the constant 10, preserve the column names in `features2_df` such that the columns in this new dataframe should be `f1` thorugh `f8`. Do not modify the column `label`. Fit a new linear model, similar to question 4, compute its root mean square error, and store it in `rmse2_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "af7de031344a62e47f17d42fd9512ba6",
     "grade": false,
     "grade_id": "cell-41b0350bc300afd9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "|  f1|      f2|      f3|      f4|      f5|      f6|      f7|      f8|         label|            features|\n",
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "|10.0|10.00008|10.45592|10.25362| 9.87122|  9.9307|  9.8526| 9.46264|-106.947151761|[10.0,10.00008,10...|\n",
      "|10.0| 9.99999|10.10405| 9.82953|10.10127|10.13776|10.66619|10.32221| 127.061566761|[10.0,9.99999,10....|\n",
      "|11.0| 9.99999| 9.27606|10.31161|10.06975| 10.0086| 9.55183| 9.77024|-170.222653879|[11.0,9.99999,9.2...|\n",
      "+----+--------+--------+--------+--------+--------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761| -98.13736777938902|\n",
      "| 127.061566761|  107.1452447141055|\n",
      "|-170.222653879|-164.65767319733277|\n",
      "|-127.850350049|-108.04179990105331|\n",
      "|-110.295233798| -109.9354533040896|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.559762278445925|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "requests_df2 = requests_df.select(requests_df[\"f1\"]+10, requests_df[\"f2\"]+10, requests_df[\"f3\"]+10,requests_df[\"f4\"]+10, requests_df[\"f5\"]+10, requests_df[\"f6\"]+10, requests_df[\"f7\"]+10, requests_df[\"f8\"]+10, requests_df[\"label\"])\n",
    "cols2 = [\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"label\"]\n",
    "req2 = requests_df2.toDF(*cols2)\n",
    "\n",
    "va2 = VectorAssembler(inputCols=[\"f1\", \"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\"],outputCol=\"features\")\n",
    "features_df2 = va.transform(req2)\n",
    "features_df2.show(3)\n",
    "\n",
    "lr2 = regression.LinearRegression(featuresCol=\"features\",labelCol=\"label\",maxIter=10, regParam=0.4, elasticNetParam=0.9)\n",
    "lr_model2 = lr.fit(features_df2)\n",
    "\n",
    "predictions2_df = lr_model2.transform(features_df2)\n",
    "predictions2_df = predictions2_df.select(\"label\",\"prediction\")\n",
    "predictions2_df.show(5)\n",
    "\n",
    "rms2 = predictions2_df.withColumn(\"error\",(predictions2_df[\"prediction\"]-predictions2_df[\"label\"]))\n",
    "rms2 = rms2.withColumn(\"squared error\",(rms2[\"error\"]**2))\n",
    "\n",
    "rmse2_df = rms2.groupBy().agg({\"squared error\":\"sum\"})\n",
    "n2 = rms2.groupBy().agg({\"error\":\"count\"}).collect()[0][0]\n",
    "\n",
    "rmse2_df = rmse2_df.withColumn(\"rmse\", fn.sqrt((1/n*rmse2_df[\"sum(squared error)\"])))\n",
    "rmse2_df = rmse2_df.drop(\"sum(squared error)\")\n",
    "rmse2_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c26d79182d21ff9debc8f3c25934d7f8",
     "grade": true,
     "grade_id": "cell-978de063c691abb7",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions2_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions2_df.count(), 10000)\n",
    "np.testing.assert_equal(type(va2), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(lr_model2), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_less(rmse2_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the root mean squared error of Q5 and Q6. They should be almost exactly the same. Also, compare the coefficients and intercepts of `lr_model` and `lr_model2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Q5\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.559748270091829|\n",
      "+-----------------+\n",
      "\n",
      "RMSE Q6\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.559762278445925|\n",
      "+-----------------+\n",
      "\n",
      "intercept lr_model -28.66290591131293\n",
      "intercept lr_model2 -1661461.0943377328\n",
      "coefficients lr_model [17.386615157246727,165401.2576977343,141.53607850862386,0.0,0.0,358.0885257641787,0.0,227.81736205585145]\n",
      "coefficients lr_model2 [17.386612760053062,165398.41455542966,141.53609398619864,0.0,0.0,358.08852403795674,0.0,227.81735682599646]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE Q5\")\n",
    "rmse_df.show()\n",
    "print(\"RMSE Q6\")\n",
    "rmse2_df.show()\n",
    "print(\"intercept lr_model\", lr_model.intercept)\n",
    "print(\"intercept lr_model2\", lr_model2.intercept)\n",
    "print(\"coefficients lr_model\", lr_model.coefficients)\n",
    "print(\"coefficients lr_model2\", lr_model2.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 pts for your answer below:** Comment on why there are differences or similarities between coefficients, intercepts, RMSE, even though we modified the features. You can use [Latex in Markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTeX-equations) to put some math into your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cd5984ba2cba0e00d13e96234557af17",
     "grade": true,
     "grade_id": "cell-29b2a054968a563c",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Coefficients**: Does not change much, because changing the data-points' value by 10 does not change the slope of the linear model.\n",
    "\n",
    "**Intercepts**: The increase in the value of data-points by 10 has led to an increase in the intercept, which will be the 10*(Coefficients)\n",
    "\n",
    "$y = b_0 + b_1x_1 + b_2x_2 + b_3x_3$ changes to $y = b_0+b_1(x_1+10)+b_2(x_2+10)+b_3(x_3+10)=(b_0+10b_1+10b_2+10b_3)b_1x_1+b_2x_2+b_3x_3$ which is added to the intercept.\n",
    "\n",
    "**RMSE**: Does not change much, because deviation from the regression line does not change by increasing the values of $x_1, x_2, and x_3$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
