{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline, pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the Mid-atlantic wage dataset (https://rdrr.io/cran/ISLR/man/Wage.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "13b497143a441ab980a4d0df52131055",
     "grade": false,
     "grade_id": "cell-3969fb69476d2b82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- maritl: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- jobclass: string (nullable = true)\n",
      " |-- health: string (nullable = true)\n",
      " |-- health_ins: string (nullable = true)\n",
      " |-- wage: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read-only\n",
    "drop_cols = ['_c0', 'logwage', 'sex', 'region']\n",
    "wage_df = spark.read.csv('/datasets/ISLR/Wage.csv', header=True, inferSchema=True).drop(*drop_cols)\n",
    "training_df, validation_df, testing_df = wage_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "wage_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>maritl</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>jobclass</th>\n",
       "      <th>health</th>\n",
       "      <th>health_ins</th>\n",
       "      <th>wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>18</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>1. &lt; HS Grad</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>75.043154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>70.476020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>45</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>130.982177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>43</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>154.685293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>50</td>\n",
       "      <td>4. Divorced</td>\n",
       "      <td>1. White</td>\n",
       "      <td>2. HS Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>75.043154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>54</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>127.115744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>44</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>4. Other</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>169.528538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>30</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>111.720849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006</td>\n",
       "      <td>41</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>2. Black</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>118.884359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004</td>\n",
       "      <td>52</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>2. HS Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>128.680488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  age            maritl      race        education        jobclass  \\\n",
       "0  2006   18  1. Never Married  1. White     1. < HS Grad   1. Industrial   \n",
       "1  2004   24  1. Never Married  1. White  4. College Grad  2. Information   \n",
       "2  2003   45        2. Married  1. White  3. Some College   1. Industrial   \n",
       "3  2003   43        2. Married  3. Asian  4. College Grad  2. Information   \n",
       "4  2005   50       4. Divorced  1. White       2. HS Grad  2. Information   \n",
       "5  2008   54        2. Married  1. White  4. College Grad  2. Information   \n",
       "6  2009   44        2. Married  4. Other  3. Some College   1. Industrial   \n",
       "7  2008   30  1. Never Married  3. Asian  3. Some College  2. Information   \n",
       "8  2006   41  1. Never Married  2. Black  3. Some College  2. Information   \n",
       "9  2004   52        2. Married  1. White       2. HS Grad  2. Information   \n",
       "\n",
       "           health health_ins        wage  \n",
       "0       1. <=Good      2. No   75.043154  \n",
       "1  2. >=Very Good      2. No   70.476020  \n",
       "2       1. <=Good     1. Yes  130.982177  \n",
       "3  2. >=Very Good     1. Yes  154.685293  \n",
       "4       1. <=Good     1. Yes   75.043154  \n",
       "5  2. >=Very Good     1. Yes  127.115744  \n",
       "6  2. >=Very Good     1. Yes  169.528538  \n",
       "7       1. <=Good     1. Yes  111.720849  \n",
       "8  2. >=Very Good     1. Yes  118.884359  \n",
       "9  2. >=Very Good     1. Yes  128.680488  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "wage_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Codify the data using transformers (20 pts)\n",
    "\n",
    "Create a fitted pipeline to the entire data `wage_df` and call it `pipe_feat`. This pipeline should codify the columns `maritl`, `race`, `education`, `jobclass`, `health`, and `health_ins`. The codification should be a combination of a `StringIndexer` and a `OneHotEncoder`. For example, for `maritl`, `StringIndexer` should create a column `maritl_index` and `OneHotEncoder` should create a column `maritl_feat`. Investigate the parameters of `StringIndexer` so that the labels are indexed alphabetically in ascending order so that, for example, the 1st index for `maritl_index` corresponds to `1. Never Married`, the 2nd index corresponds to `2. Married`, and so forth. Also, investigate the parameters of  `OneHotEncoder` so that there are no columns dropped as it is usually done for dummy variables. This is, marital status should have one column for each of the classes.\n",
    "\n",
    "The pipeline should create a column `features` that combines `year`, `age`, and all codified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b6f4272b29b08b91879e9ceff83ffde9",
     "grade": false,
     "grade_id": "cell-06ca40bbc2363d61",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create `pipe_feat` below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Chose only categorical columns\n",
    "categorical_cols = wage_df.columns[2:8]\n",
    "\n",
    "# String indexer model\n",
    "string_indexer = [feature.StringIndexer(inputCol=c,outputCol=c+'_index') for c in categorical_cols]\n",
    "\n",
    "# One Hot Encoder model\n",
    "onehot_encoder = [feature.OneHotEncoder(inputCol=c+'_index',outputCol=c+'_feat') for c in categorical_cols]\n",
    "\n",
    "# Building the feature model using Vector assembler\n",
    "feature_col = [c+'_feat' for c in categorical_cols]\n",
    "feature_col += [c+'_index' for c in categorical_cols]\n",
    "feature_col += [\"year\",\"age\"]\n",
    "\n",
    "vector_assembler = feature.VectorAssembler(inputCols = feature_col, outputCol = 'features')\n",
    "\n",
    "# Combining all the stages\n",
    "all_stages = string_indexer + onehot_encoder + [vector_assembler]\n",
    "\n",
    "# Building the fitted pipeline\n",
    "pipe_feat = Pipeline(stages=all_stages).fit(wage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2006</td>\n",
       "      <td>2004</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl</th>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>4. Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>1. White</td>\n",
       "      <td>1. White</td>\n",
       "      <td>1. White</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>1. White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>1. &lt; HS Grad</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. HS Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass</th>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins</th>\n",
       "      <td>2. No</td>\n",
       "      <td>2. No</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>1. Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>75.0432</td>\n",
       "      <td>70.476</td>\n",
       "      <td>130.982</td>\n",
       "      <td>154.685</td>\n",
       "      <td>75.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl_index</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_index</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_index</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass_index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_index</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins_index</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl_feat</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_feat</th>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_feat</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass_feat</th>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_feat</th>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins_feat</th>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  0  \\\n",
       "year                                                           2006   \n",
       "age                                                              18   \n",
       "maritl                                             1. Never Married   \n",
       "race                                                       1. White   \n",
       "education                                              1. < HS Grad   \n",
       "jobclass                                              1. Industrial   \n",
       "health                                                    1. <=Good   \n",
       "health_ins                                                    2. No   \n",
       "wage                                                        75.0432   \n",
       "maritl_index                                                      1   \n",
       "race_index                                                        0   \n",
       "education_index                                                   4   \n",
       "jobclass_index                                                    0   \n",
       "health_index                                                      1   \n",
       "health_ins_index                                                  1   \n",
       "maritl_feat                                    (0.0, 1.0, 0.0, 0.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "education_feat                                 (0.0, 0.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (1.0)   \n",
       "health_feat                                                   (0.0)   \n",
       "health_ins_feat                                               (0.0)   \n",
       "features          (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                                  1  \\\n",
       "year                                                           2004   \n",
       "age                                                              24   \n",
       "maritl                                             1. Never Married   \n",
       "race                                                       1. White   \n",
       "education                                           4. College Grad   \n",
       "jobclass                                             2. Information   \n",
       "health                                               2. >=Very Good   \n",
       "health_ins                                                    2. No   \n",
       "wage                                                         70.476   \n",
       "maritl_index                                                      1   \n",
       "race_index                                                        0   \n",
       "education_index                                                   1   \n",
       "jobclass_index                                                    1   \n",
       "health_index                                                      0   \n",
       "health_ins_index                                                  1   \n",
       "maritl_feat                                    (0.0, 1.0, 0.0, 0.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "education_feat                                 (0.0, 1.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (0.0)   \n",
       "health_feat                                                   (1.0)   \n",
       "health_ins_feat                                               (0.0)   \n",
       "features          (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "\n",
       "                                                                  2  \\\n",
       "year                                                           2003   \n",
       "age                                                              45   \n",
       "maritl                                                   2. Married   \n",
       "race                                                       1. White   \n",
       "education                                           3. Some College   \n",
       "jobclass                                              1. Industrial   \n",
       "health                                                    1. <=Good   \n",
       "health_ins                                                   1. Yes   \n",
       "wage                                                        130.982   \n",
       "maritl_index                                                      0   \n",
       "race_index                                                        0   \n",
       "education_index                                                   2   \n",
       "jobclass_index                                                    0   \n",
       "health_index                                                      1   \n",
       "health_ins_index                                                  0   \n",
       "maritl_feat                                    (1.0, 0.0, 0.0, 0.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "education_feat                                 (0.0, 0.0, 1.0, 0.0)   \n",
       "jobclass_feat                                                 (1.0)   \n",
       "health_feat                                                   (0.0)   \n",
       "health_ins_feat                                               (1.0)   \n",
       "features          (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                                  3  \\\n",
       "year                                                           2003   \n",
       "age                                                              43   \n",
       "maritl                                                   2. Married   \n",
       "race                                                       3. Asian   \n",
       "education                                           4. College Grad   \n",
       "jobclass                                             2. Information   \n",
       "health                                               2. >=Very Good   \n",
       "health_ins                                                   1. Yes   \n",
       "wage                                                        154.685   \n",
       "maritl_index                                                      0   \n",
       "race_index                                                        2   \n",
       "education_index                                                   1   \n",
       "jobclass_index                                                    1   \n",
       "health_index                                                      0   \n",
       "health_ins_index                                                  0   \n",
       "maritl_feat                                    (1.0, 0.0, 0.0, 0.0)   \n",
       "race_feat                                           (0.0, 0.0, 1.0)   \n",
       "education_feat                                 (0.0, 1.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (0.0)   \n",
       "health_feat                                                   (1.0)   \n",
       "health_ins_feat                                               (1.0)   \n",
       "features          (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...   \n",
       "\n",
       "                                                                  4  \n",
       "year                                                           2005  \n",
       "age                                                              50  \n",
       "maritl                                                  4. Divorced  \n",
       "race                                                       1. White  \n",
       "education                                                2. HS Grad  \n",
       "jobclass                                             2. Information  \n",
       "health                                                    1. <=Good  \n",
       "health_ins                                                   1. Yes  \n",
       "wage                                                        75.0432  \n",
       "maritl_index                                                      2  \n",
       "race_index                                                        0  \n",
       "education_index                                                   0  \n",
       "jobclass_index                                                    1  \n",
       "health_index                                                      1  \n",
       "health_ins_index                                                  0  \n",
       "maritl_feat                                    (0.0, 0.0, 1.0, 0.0)  \n",
       "race_feat                                           (1.0, 0.0, 0.0)  \n",
       "education_feat                                 (1.0, 0.0, 0.0, 0.0)  \n",
       "jobclass_feat                                                 (0.0)  \n",
       "health_feat                                                   (0.0)  \n",
       "health_ins_feat                                               (1.0)  \n",
       "features          (0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the results\n",
    "pipe_feat.transform(wage_df).limit(5).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5fa22305ca72ca8f8009792f166f24d",
     "grade": true,
     "grade_id": "cell-f021fdae60597e9f",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (20 pts)\n",
    "assert set(type(pm) for pm in pipe_feat.stages) == {feature.OneHotEncoder, feature.StringIndexerModel, feature.VectorAssembler}\n",
    "assert len(pipe_feat.transform(wage_df).first().features) == 22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: (15 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forest regressions that take in all features from the `wage_df` to predict `wage`. These pipelines should have as first stage the pipeline created in question 1 and should be fitted to the training data.\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=1` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "937fda91b6f78f26ff1cefcb0f4766f3",
     "grade": false,
     "grade_id": "cell-81a05842530a4bf5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipelines `pipe_rf1`, `pipe_rf2`, and `pipe_rf3` here\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Random Forest regressor models\n",
    "rf1 = regression.RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",predictionCol=\"prediction\",maxDepth=1,numTrees=60)\n",
    "rf2 = regression.RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",predictionCol=\"prediction\",maxDepth=3,numTrees=40)\n",
    "rf3 = regression.RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",predictionCol=\"prediction\",maxDepth=6,numTrees=20)\n",
    "\n",
    "# Fitted pipelines,with first stage being the created pipeline and the second stage being the random forest regressor\n",
    "pipe_rf1 = Pipeline(stages=[pipe_feat,rf1]).fit(training_df)\n",
    "pipe_rf2 = Pipeline(stages=[pipe_feat,rf2]).fit(training_df)\n",
    "pipe_rf3 = Pipeline(stages=[pipe_feat,rf3]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "918062cd396f3a9c3ebda974d405802c",
     "grade": true,
     "grade_id": "cell-af70c6d07ebf40ef",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 15 pts\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (10 pts)\n",
    "\n",
    "Use the following evaluator to compute the RMSE of the models on validation data. Print the RMSE of the three models and assign the best one (i.e., the best pipeline) to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73cc7671f0711e342716e8875324b1ca",
     "grade": false,
     "grade_id": "cell-1f8bd4cfa96e326a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.RegressionEvaluator(labelCol='wage', metricName='rmse')\n",
    "# use it as follows:\n",
    "#   evaluator.evaluate(fitted_pipeline.transform(df)) -> RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c21368329ee32c72847a9261925e586",
     "grade": false,
     "grade_id": "cell-2e53b6ab6e82f38d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.202853882645535\n",
      "33.617519747629125\n",
      "33.44699490860644\n"
     ]
    }
   ],
   "source": [
    "# print MSE of each model and define `best_model`\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Calculated the RMSE for all the three pipelines, for the validation set\n",
    "rmse1 = evaluator.evaluate(pipe_rf1.transform(validation_df))\n",
    "print(rmse1)\n",
    "rmse2 = evaluator.evaluate(pipe_rf2.transform(validation_df))\n",
    "print(rmse2)\n",
    "rmse3 = evaluator.evaluate(pipe_rf3.transform(validation_df))\n",
    "print(rmse3)\n",
    "\n",
    "# Assigned the pipeline with lowest RMSE to the best model\n",
    "best_model = pipe_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e626dc1e89241ad46546ac559e951ca7",
     "grade": true,
     "grade_id": "cell-c87098fdf26d5f77",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(best_model.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(best_model.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 5 pts\n",
    "\n",
    "Compute the RMSE of the model on testing data, print it, and assign it to variable `RMSE_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f64d0e15006450b30465eba9c04809b",
     "grade": false,
     "grade_id": "cell-975307604e1c7a37",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.28723242088405\n"
     ]
    }
   ],
   "source": [
    "# create RMSE_best below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Used the best model on the test data, and calculated the RMSE\n",
    "RMSE_best = evaluator.evaluate(best_model.transform(testing_df))\n",
    "print(RMSE_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1352035aa1251f5f3dbdd1eaa97378d3",
     "grade": true,
     "grade_id": "cell-79c466e618817e90",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_array_less(RMSE_best, 40)\n",
    "np.testing.assert_array_less(30, RMSE_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: 5 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`wage_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f1029e0fa09318af8175fcdcd931eca9",
     "grade": false,
     "grade_id": "cell-6a682b3fdbb9ff9c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create final_model pipeline below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Created the final model, which fit the entire dataset using the stages of best_model\n",
    "final_model = Pipeline(stages=[best_model.stages[0],best_model.stages[1]]).fit(wage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PipelineModel_3884e0caa527,\n",
       " RandomForestRegressionModel (uid=RandomForestRegressor_463cb1b263d6) with 20 trees]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the stages of the final model\n",
    "final_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56d5b234a9fc45e110683dc01ae7dffa",
     "grade": true,
     "grade_id": "cell-803d8872aeb9cc8f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_equal(type(final_model.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(final_model.transform(wage_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: 30 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains the names of the features. Give appropriate column names such as `maritl_1._Never_Married`. You can build these feature names by using the labels from the fitted `StringIndexer` used in Question 1. Use as feature importance as determined by the random forest of the final model (`final_model`). Sort the pandas dataframe by `importance` in descending order and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = []\n",
    "# for key, value in dr1.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "\n",
    "# for key, value in dr2.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "    \n",
    "# for key, value in dr3.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "    \n",
    "# for key, value in dr4.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "    \n",
    "# for key, value in dr5.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "\n",
    "# for key, value in dr6.items():\n",
    "#     temp = [key, value]\n",
    "#     f.append(temp)\n",
    "    \n",
    "# feature_importance = pd.DataFrame(f,columns = [\"features\",\"importance\"])\n",
    "\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f05a027040f4b4b04272173270dcc9b",
     "grade": false,
     "grade_id": "cell-0f7185f318626a45",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "# Returning the feature importances of the random forest model\n",
    "\n",
    "# Imported chain function from itertools\n",
    "#!pip install more-itertools\n",
    "from itertools import chain\n",
    "\n",
    "# Fit the pipeline on the training data, and used the final model\n",
    "pipe = final_model.stages[0].transform(wage_df)\n",
    "postrf_df = rf3.fit(pipe)\n",
    "\n",
    "# Identified the various feature importances for the values \n",
    "feature_imp = postrf_df.featureImportances\n",
    "feat = postrf_df.transform(pipe)\n",
    "\n",
    "# Assigning the sorted values of the feature importances to the variable attrs\n",
    "attrs = sorted(\n",
    "    (attr[\"idx\"], attr[\"name\"]) for attr in (chain(*feat\n",
    "        .schema[\"features\"]\n",
    "        .metadata[\"ml_attr\"][\"attrs\"].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_index</td>\n",
       "      <td>0.317070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education_feat_5. Advanced Degree</td>\n",
       "      <td>0.132371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>health_ins_feat_1. Yes</td>\n",
       "      <td>0.091746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>age</td>\n",
       "      <td>0.083808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>health_ins_index</td>\n",
       "      <td>0.073294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>maritl_index</td>\n",
       "      <td>0.070556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>education_feat_4. College Grad</td>\n",
       "      <td>0.037428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>year</td>\n",
       "      <td>0.029142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education_feat_2. HS Grad</td>\n",
       "      <td>0.028323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maritl_feat_1. Never Married</td>\n",
       "      <td>0.025999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maritl_feat_2. Married</td>\n",
       "      <td>0.025525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>education_feat_3. Some College</td>\n",
       "      <td>0.014430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jobclass_feat_1. Industrial</td>\n",
       "      <td>0.013539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>race_index</td>\n",
       "      <td>0.013147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>health_index</td>\n",
       "      <td>0.011206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jobclass_index</td>\n",
       "      <td>0.011112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>health_feat_2. &gt;=Very Good</td>\n",
       "      <td>0.006949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race_feat_2. Black</td>\n",
       "      <td>0.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race_feat_1. White</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>race_feat_3. Asian</td>\n",
       "      <td>0.002507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maritl_feat_4. Divorced</td>\n",
       "      <td>0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maritl_feat_5. Separated</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance\n",
       "16                    education_index    0.317070\n",
       "10  education_feat_5. Advanced Degree    0.132371\n",
       "13             health_ins_feat_1. Yes    0.091746\n",
       "21                                age    0.083808\n",
       "19                   health_ins_index    0.073294\n",
       "14                       maritl_index    0.070556\n",
       "8      education_feat_4. College Grad    0.037428\n",
       "20                               year    0.029142\n",
       "7           education_feat_2. HS Grad    0.028323\n",
       "1        maritl_feat_1. Never Married    0.025999\n",
       "0              maritl_feat_2. Married    0.025525\n",
       "9      education_feat_3. Some College    0.014430\n",
       "11        jobclass_feat_1. Industrial    0.013539\n",
       "15                         race_index    0.013147\n",
       "18                       health_index    0.011206\n",
       "17                     jobclass_index    0.011112\n",
       "12         health_feat_2. >=Very Good    0.006949\n",
       "5                  race_feat_2. Black    0.004099\n",
       "4                  race_feat_1. White    0.003175\n",
       "6                  race_feat_3. Asian    0.002507\n",
       "2             maritl_feat_4. Divorced    0.002365\n",
       "3            maritl_feat_5. Separated    0.002209"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of all the feature names, and their respective values\n",
    "a = [(name, postrf_df.featureImportances[idx])\n",
    " for idx, name in attrs\n",
    " if postrf_df.featureImportances[idx]]\n",
    "\n",
    "# Building the dataframe out of the list of feature names and values, renaming the columns, and sorting them in descending order\n",
    "feature_importance = pd.DataFrame(a)\n",
    "feature_importance.columns = ['feature','importance']\n",
    "feature_importance = feature_importance.sort_values('importance',ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "# Tried to change the name of the columns as per the specifications, but no regex expression fit the requirements\n",
    "#######################################################################################################################\n",
    "\n",
    "# edu_values=list(wage_df.toPandas().education.unique())\n",
    "# edu_dir={}\n",
    "# for ele in edu_values:\n",
    "#     edu_dir[int(ele[0])]=ele\n",
    "# print(edu_dir)\n",
    "\n",
    "# race_values=list(wage_df.toPandas().race.unique())\n",
    "# race_dir = {}\n",
    "# for ele in race_values:\n",
    "#     race_dir[int(ele[0])]=ele\n",
    "# print(race_dir)\n",
    "\n",
    "# maritl_values=list(wage_df.toPandas().maritl.unique())\n",
    "# maritl_dir = {}\n",
    "# for ele in maritl_values:\n",
    "#     maritl_dir[int(ele[0])]=ele\n",
    "# print(maritl_dir)\n",
    "\n",
    "# jobclass_values=list(wage_df.toPandas().jobclass.unique())\n",
    "# jobclass_dir = {}\n",
    "# for ele in jobclass_values:\n",
    "#     jobclass_dir[int(ele[0])]=ele\n",
    "# print(jobclass_dir)\n",
    "\n",
    "# health_values=list(wage_df.toPandas().health.unique())\n",
    "# health_dir = {}\n",
    "# for ele in health_values:\n",
    "#     health_dir[int(ele[0])]=ele\n",
    "# print(health_dir)\n",
    "\n",
    "# health_ins_values=list(wage_df.toPandas().health_ins.unique())\n",
    "# health_ins_dir = {}\n",
    "# for ele in health_ins_values:\n",
    "#     health_ins_dir[int(ele[0])]=ele\n",
    "# print(health_ins_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'education_feat_4. College Grad': 0.2991217048703026, 'education_feat_3. Some College': 0.015599903745202131, 'education_feat_2. HS Grad': 0.01312854815331528, 'education_feat_5. Advanced Degree': 0.009456500988297544, 'education_feat_1. < HS Grad': 0.0052934928295298835}\n",
      "{'race_feat_2. Black': 0.06454927286165087, 'race_feat_3. Asian': 0.052493458043539824, 'race_feat_1. White': 0.0001209745135330191}\n",
      "{'maritl_feat_4. Divorced': 0.14902578576404216, 'maritl_feat_2. Married': 0.04386079962086879, 'maritl_feat_5. Separated': 0.014966275072135401, 'maritl_feat_1. Never Married': 0.0036178147587944787}\n",
      "{'jobclass_feat_1. Industrial': 0.003444107108784947}\n",
      "{'health_feat_1. <=Good': 0.043042763162742026}\n",
      "{'health_ins_feat_1. Yes': 0.0992499239804704, 'health_ins_feat_2. No': 0.018427146210230692}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "edu_idx=edu_dir.keys()\n",
    "edu_list=[]\n",
    "dr1={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"education\",ele):\n",
    "        edu_list.append(ele)\n",
    "        dr1[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in edu_idx:\n",
    "    for col in edu_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "edu_list[-1]=\"education_feat_\"+str(edu_dir[int(miss)])\n",
    "dr1_keys=list(dr1.keys())\n",
    "dr1[edu_list[-1]]=dr1.pop(dr1_keys[-1])\n",
    "print(dr1)\n",
    "\n",
    "race_idx=race_dir.keys()\n",
    "race_list=[]\n",
    "dr2={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"race\",ele):\n",
    "        race_list.append(ele)\n",
    "        dr2[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in race_idx:\n",
    "    for col in race_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "race_list[-1]=\"race_feat_\"+str(race_dir[int(miss)])\n",
    "dr2_keys=list(dr2.keys())\n",
    "dr2[race_list[-1]]=dr2.pop(dr2_keys[-1])\n",
    "print(dr2)\n",
    "\n",
    "maritl_idx=maritl_dir.keys()\n",
    "maritl_list=[]\n",
    "dr3={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"maritl\",ele):\n",
    "        maritl_list.append(ele)\n",
    "        dr3[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in maritl_idx:\n",
    "    for col in maritl_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "maritl_list[-1]=\"maritl_feat_\"+str(maritl_dir[int(miss)])\n",
    "dr3_keys=list(dr3.keys())\n",
    "dr3[maritl_list[-1]]=dr3.pop(dr3_keys[-1])\n",
    "print(dr3)\n",
    "\n",
    "jobclass_idx=jobclass_dir.keys()\n",
    "jobclass_list=[]\n",
    "dr4={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"jobclass\",ele):\n",
    "        jobclass_list.append(ele)\n",
    "        dr4[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in jobclass_idx:\n",
    "    for col in jobclass_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "jobclass_list[-1]=\"jobclass_feat_\"+str(jobclass_dir[int(miss)])\n",
    "dr4_keys=list(dr4.keys())\n",
    "dr4[jobclass_list[-1]]=dr4.pop(dr4_keys[-1])\n",
    "print(dr4)\n",
    "\n",
    "health_idx=health_dir.keys()\n",
    "health_list=[]\n",
    "dr5={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"health_feat\",ele):\n",
    "        health_list.append(ele)\n",
    "        dr5[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in health_idx:\n",
    "    for col in health_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "health_list[-1]=\"health_feat_\"+str(health_dir[int(miss)])\n",
    "dr5_keys=list(dr5.keys())\n",
    "dr5[health_list[-1]]=dr5.pop(dr5_keys[-1])\n",
    "print(dr5)\n",
    "\n",
    "health_ins_idx=health_ins_dir.keys()\n",
    "health_ins_list=[]\n",
    "dr6={}\n",
    "for ele in list(feature_importance1[\"feature\"].unique()):\n",
    "    if re.search(\"health_ins\",ele):\n",
    "        health_ins_list.append(ele)\n",
    "        dr6[str(ele)]=float(feature_importance1.loc[feature_importance1[\"feature\"]==ele,\"importance\"])\n",
    "flag=0\n",
    "for idx in health_ins_idx:\n",
    "    for col in health_ins_list:\n",
    "        if str(idx) in col:\n",
    "            flag=1\n",
    "            break\n",
    "    if flag==0:\n",
    "        miss=idx\n",
    "\n",
    "health_ins_list[1]=\"health_ins_feat_\"+str(health_ins_dir[int(miss)])\n",
    "dr6_keys=list(dr6.keys())\n",
    "dr6[health_ins_list[-1]]=dr6.pop(dr6_keys[-1])\n",
    "print(dr6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65a7424b40deec2e714bd3764fb56667",
     "grade": true,
     "grade_id": "cell-dc3926e469167f5e",
     "locked": true,
     "points": 25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 25 pts\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the titanic dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36878e68cb44923cdebab7fbd3f69660",
     "grade": true,
     "grade_id": "cell-21e30d00198bae80",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7:  15 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and add comments to the cell describing how you think this particular tree is fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a60948658565a5116e4b3e8bb7e602b4",
     "grade": false,
     "grade_id": "cell-bf4e4b6323d9fcb5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Using the 8th tree for evaluating how the particular tree fits the data\n",
    "example_tree = final_model.stages[1].trees[8].toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel (uid=dtr_e0d332c284ac) of depth 6 with 119 nodes\n",
      "  If (feature 16 in {0.0,2.0,4.0})\n",
      "   If (feature 13 in {0.0})\n",
      "    If (feature 21 <= 28.5)\n",
      "     If (feature 0 in {0.0})\n",
      "      If (feature 21 <= 24.5)\n",
      "       If (feature 16 in {2.0,4.0})\n",
      "        Predict: 62.44825501585237\n",
      "       Else (feature 16 not in {2.0,4.0})\n",
      "        Predict: 70.02706576550946\n",
      "      Else (feature 21 > 24.5)\n",
      "       If (feature 4 in {0.0})\n",
      "        Predict: 62.96143718082374\n",
      "       Else (feature 4 not in {0.0})\n",
      "        Predict: 76.80127438255825\n",
      "     Else (feature 0 not in {0.0})\n",
      "      If (feature 21 <= 24.5)\n",
      "       If (feature 16 in {0.0})\n",
      "        Predict: 67.22541563344623\n",
      "       Else (feature 16 not in {0.0})\n",
      "        Predict: 137.7644514573805\n",
      "      Else (feature 21 > 24.5)\n",
      "       If (feature 4 in {1.0})\n",
      "        Predict: 70.6756099066326\n",
      "       Else (feature 4 not in {1.0})\n",
      "        Predict: 80.0801440199342\n",
      "    Else (feature 21 > 28.5)\n",
      "     If (feature 9 in {0.0})\n",
      "      If (feature 6 in {1.0})\n",
      "       If (feature 7 in {0.0})\n",
      "        Predict: 59.854501874244455\n",
      "       Else (feature 7 not in {0.0})\n",
      "        Predict: 70.88671932612007\n",
      "      Else (feature 6 not in {1.0})\n",
      "       If (feature 21 <= 42.5)\n",
      "        Predict: 93.75979855574542\n",
      "       Else (feature 21 > 42.5)\n",
      "        Predict: 79.5445296415823\n",
      "     Else (feature 9 not in {0.0})\n",
      "      If (feature 18 in {1.0})\n",
      "       If (feature 14 in {1.0,2.0})\n",
      "        Predict: 68.60939905462845\n",
      "       Else (feature 14 not in {1.0,2.0})\n",
      "        Predict: 98.385240154589\n",
      "      Else (feature 18 not in {1.0})\n",
      "       If (feature 1 in {1.0})\n",
      "        Predict: 73.48025231776548\n",
      "       Else (feature 1 not in {1.0})\n",
      "        Predict: 125.27542208535922\n",
      "   Else (feature 13 not in {0.0})\n",
      "    If (feature 14 in {1.0,3.0})\n",
      "     If (feature 16 in {0.0,4.0})\n",
      "      If (feature 21 <= 29.5)\n",
      "       If (feature 16 in {0.0})\n",
      "        Predict: 78.70596825936232\n",
      "       Else (feature 16 not in {0.0})\n",
      "        Predict: 85.62838020074832\n",
      "      Else (feature 21 > 29.5)\n",
      "       If (feature 17 in {1.0})\n",
      "        Predict: 84.68521267990286\n",
      "       Else (feature 17 not in {1.0})\n",
      "        Predict: 87.54193213434036\n",
      "     Else (feature 16 not in {0.0,4.0})\n",
      "      If (feature 15 in {0.0,1.0,2.0})\n",
      "       If (feature 21 <= 34.5)\n",
      "        Predict: 89.92300076588977\n",
      "       Else (feature 21 > 34.5)\n",
      "        Predict: 103.63381581203927\n",
      "      Else (feature 15 not in {0.0,1.0,2.0})\n",
      "       Predict: 132.86076531157187\n",
      "    Else (feature 14 not in {1.0,3.0})\n",
      "     If (feature 16 in {0.0,4.0})\n",
      "      If (feature 20 <= 2007.5)\n",
      "       If (feature 12 in {0.0})\n",
      "        Predict: 94.3038138552448\n",
      "       Else (feature 12 not in {0.0})\n",
      "        Predict: 104.42426095871369\n",
      "      Else (feature 20 > 2007.5)\n",
      "       If (feature 16 in {4.0})\n",
      "        Predict: 93.79660085065338\n",
      "       Else (feature 16 not in {4.0})\n",
      "        Predict: 112.8049993214849\n",
      "     Else (feature 16 not in {0.0,4.0})\n",
      "      If (feature 4 in {0.0})\n",
      "       If (feature 21 <= 34.5)\n",
      "        Predict: 79.2498206816396\n",
      "       Else (feature 21 > 34.5)\n",
      "        Predict: 113.75119540852873\n",
      "      Else (feature 4 not in {0.0})\n",
      "       If (feature 21 <= 29.5)\n",
      "        Predict: 94.30839996123818\n",
      "       Else (feature 21 > 29.5)\n",
      "        Predict: 118.5261205362054\n",
      "  Else (feature 16 not in {0.0,2.0,4.0})\n",
      "   If (feature 14 in {1.0,2.0,3.0,4.0})\n",
      "    If (feature 19 in {1.0})\n",
      "     If (feature 16 in {1.0})\n",
      "      If (feature 20 <= 2005.5)\n",
      "       If (feature 15 in {3.0})\n",
      "        Predict: 38.2235828218228\n",
      "       Else (feature 15 not in {3.0})\n",
      "        Predict: 78.041243178942\n",
      "      Else (feature 20 > 2005.5)\n",
      "       If (feature 21 <= 40.5)\n",
      "        Predict: 95.48196894027228\n",
      "       Else (feature 21 > 40.5)\n",
      "        Predict: 60.1669314059518\n",
      "     Else (feature 16 not in {1.0})\n",
      "      If (feature 17 in {0.0})\n",
      "       If (feature 20 <= 2003.5)\n",
      "        Predict: 143.134940811134\n",
      "       Else (feature 20 > 2003.5)\n",
      "        Predict: 81.28325328425268\n",
      "      Else (feature 17 not in {0.0})\n",
      "       Predict: 182.020620963512\n",
      "    Else (feature 19 not in {1.0})\n",
      "     If (feature 15 in {0.0})\n",
      "      If (feature 21 <= 43.5)\n",
      "       If (feature 20 <= 2004.5)\n",
      "        Predict: 90.0264978471826\n",
      "       Else (feature 20 > 2004.5)\n",
      "        Predict: 111.98848198354237\n",
      "      Else (feature 21 > 43.5)\n",
      "       If (feature 12 in {0.0})\n",
      "        Predict: 101.48588335838755\n",
      "       Else (feature 12 not in {0.0})\n",
      "        Predict: 128.68988332715696\n",
      "     Else (feature 15 not in {0.0})\n",
      "      If (feature 20 <= 2003.5)\n",
      "       Predict: 180.030197076236\n",
      "      Else (feature 20 > 2003.5)\n",
      "       If (feature 5 in {0.0})\n",
      "        Predict: 116.41480375797804\n",
      "       Else (feature 5 not in {0.0})\n",
      "        Predict: 131.04306456165816\n",
      "   Else (feature 14 not in {1.0,2.0,3.0,4.0})\n",
      "    If (feature 16 in {1.0})\n",
      "     If (feature 19 in {1.0})\n",
      "      If (feature 21 <= 56.5)\n",
      "       If (feature 20 <= 2005.5)\n",
      "        Predict: 102.9017846738961\n",
      "       Else (feature 20 > 2005.5)\n",
      "        Predict: 129.4108161703991\n",
      "      Else (feature 21 > 56.5)\n",
      "       If (feature 11 in {0.0})\n",
      "        Predict: 32.3664131748549\n",
      "       Else (feature 11 not in {0.0})\n",
      "        Predict: 65.4458918678738\n",
      "     Else (feature 19 not in {1.0})\n",
      "      If (feature 11 in {0.0})\n",
      "       Predict: 134.21010574524274\n",
      "      Else (feature 11 not in {0.0})\n",
      "       If (feature 21 <= 32.5)\n",
      "        Predict: 116.15681378935092\n",
      "       Else (feature 21 > 32.5)\n",
      "        Predict: 148.44685427371115\n",
      "    Else (feature 16 not in {1.0})\n",
      "     If (feature 20 <= 2003.5)\n",
      "      If (feature 21 <= 59.5)\n",
      "       If (feature 21 <= 54.5)\n",
      "        Predict: 126.91804066410224\n",
      "       Else (feature 21 > 54.5)\n",
      "        Predict: 166.01365049399146\n",
      "      Else (feature 21 > 59.5)\n",
      "       If (feature 12 in {1.0})\n",
      "        Predict: 79.1280844956297\n",
      "       Else (feature 12 not in {1.0})\n",
      "        Predict: 118.88435933988603\n",
      "     Else (feature 20 > 2003.5)\n",
      "      If (feature 20 <= 2008.5)\n",
      "       If (feature 21 <= 35.5)\n",
      "        Predict: 126.08866752404298\n",
      "       Else (feature 21 > 35.5)\n",
      "        Predict: 176.53655046097745\n",
      "      Else (feature 20 > 2008.5)\n",
      "       If (feature 18 in {0.0})\n",
      "        Predict: 126.74442477455659\n",
      "       Else (feature 18 not in {0.0})\n",
      "        Predict: 186.78499359930294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the tree here\n",
    "print(example_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "639477f58c5b7ee916b3add4ad70c547",
     "grade": true,
     "grade_id": "cell-1c6f7a9628ad7949",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 points\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeRegressionModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Comment on the feature that is at the top of the tree. Does it make sense that that is the feature there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature at the top of the tree is the most important feature in the tree. The reason is, changes in value of the root node (first feature) can throw the prediction anywhere across the tree, as it is the first node. This means, the prediction is the most sensitive to the variable which is the most important.\n",
    "\n",
    "As per tree 8, the most important feature is 16 (education less than high-school grad) , which is the most important feature according to the feature_importances dataframe as well.  It makes sense because whether someone has education or not (basic) changes the amount of wage one can get significantly. Degrees after high-school do not carry as big a difference as educated/not-educated.\n",
    "\n",
    "NOTE: The output changes as per different random-forest trees, and in this case we are only look at the behavior of tree 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30700e9cc5ca65ee007db0f0a2a2c447",
     "grade": true,
     "grade_id": "cell-8240c5a7db1c22af",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
